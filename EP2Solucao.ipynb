{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b7ee38-7736-444d-bb68-580d9aaf557a",
   "metadata": {},
   "source": [
    "## MAC05921 – Deep Learning\n",
    "\n",
    "### DCC / IME-USP — 2024\n",
    "\n",
    "#### **EP 2** \n",
    "Treinar um modelo do tipo U-Net utilizando o dataset DRIVE para realizar a segmentação\n",
    "de imagens. Avalie o desempenho do modelo utilizando as métricas de acurácia, precision,\n",
    "recall, F1-score, IoU, e outras que julgar relevantes. Discuta os resultados obtidos, desta-\n",
    "cando quaisquer modificações realizadas no modelo ou na estratégia de treinamento para\n",
    "lidar adequadamente com o dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59505964-ec69-4666-b238-645b0ede345b",
   "metadata": {},
   "source": [
    "### **Solução:**\n",
    "#### **Tentativa 1**\n",
    "A solução foi elabora em cima do repositorio [**U-Net: Semantic segmentation with PyTorch**](https://github.com/milesial/Pytorch-UNet). (Customized implementation of the U-Net in PyTorch for Kaggle's Carvana Image Masking Challenge from high definition images.)\\\n",
    "OBS: Realizei a execução e treinamento do reposito para o problema **Carvana Image Masking Challenge** ao final do arquivo quero realizar uma comparação e ver que metricas com os dados do problema drive nele.\n",
    "Não Consegui realizar ao teração dos parametros para realizar o funcionamento com o datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c035760-6d16-4559-be7e-1c547a6b0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Erro \n",
    "INFO: Using device cuda\n",
    "INFO: Network:\n",
    "\t3 input channels\n",
    "\t2 output channels (classes)\n",
    "\tTransposed conv upscaling\n",
    "/tmp/ipykernel_82248/4225091555.py:206: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
    "  state_dict = torch.load(args.load, map_location=device)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "UnpicklingError                           Traceback (most recent call last)\n",
    "Cell In[3], line 206\n",
    "    200 logging.info(f'Network:\\n'\n",
    "    201              f'\\t{model.n_channels} input channels\\n'\n",
    "    202              f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "    203              f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
    "    205 if args.load:\n",
    "--> 206     state_dict = torch.load(args.load, map_location=device)\n",
    "    207     del state_dict['mask_values']\n",
    "    208     model.load_state_dict(state_dict)\n",
    "\n",
    "File ~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1114, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n",
    "   1112     except RuntimeError as e:\n",
    "   1113         raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
    "-> 1114 return _legacy_load(\n",
    "   1115     opened_file, map_location, pickle_module, **pickle_load_args\n",
    "   1116 )\n",
    "\n",
    "File ~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1338, in _legacy_load(f, map_location, pickle_module, **pickle_load_args)\n",
    "   1332 if not hasattr(f, 'readinto') and (3, 8, 0) <= sys.version_info < (3, 8, 2):\n",
    "   1333     raise RuntimeError(\n",
    "   1334         \"torch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \"\n",
    "   1335         f'Received object of type \"{type(f)}\". Please update to Python 3.8.2 or newer to restore this '\n",
    "   1336         \"functionality.\")\n",
    "-> 1338 magic_number = pickle_module.load(f, **pickle_load_args)\n",
    "   1339 if magic_number != MAGIC_NUMBER:\n",
    "   1340     raise RuntimeError(\"Invalid magic number; corrupt file?\")\n",
    "\n",
    "UnpicklingError: invalid load key, '{'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cd8fd-a480-4c43-bba3-1c2bb0ff39ef",
   "metadata": {},
   "source": [
    "Após diversas tentativas abandonei e resolvi trocar a abortagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdef73a-97a6-47ec-95fe-47861ad675a9",
   "metadata": {},
   "source": [
    "#### **Tentativa 2**\n",
    "A solução foi elabora em cima do repositorio [**UNet-PyTorch**](https://github.com/uygarkurt/UNet-PyTorch?tab=readme-ov-file). (Customized implementation of the U-Net in PyTorch for Kaggle's Carvana Image Masking Challenge from high definition images.)\\\n",
    "OBS: Realizei a execução e treinamento do reposito para o problema **Carvana Image Masking Challenge** ao final do arquivo quero realizar uma comparação e ver que metricas com os dados do problema drive nele.\n",
    "Não Consegui realizar ao teração dos parametros para realizar o funcionamento com o datset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d3890-5a6b-4385-8991-09b47d92f78d",
   "metadata": {},
   "source": [
    "**Problemas** \\\n",
    "O algoritmo emite um erro para imagens maiores que 128 X 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b803e18-e8c5-414d-8fc0-d07e0bfa6313",
   "metadata": {},
   "source": [
    "<font color=\"red\">torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 21.19 MiB is free. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Of the allocated memory 3.43 GiB is allocated by PyTorch, and 273.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422ce4f-803b-4025-8308-43a16c7f017b",
   "metadata": {},
   "source": [
    "**Modificações realizadas** \\\n",
    "Main\n",
    "<ol>\n",
    "  <li>Redimencionamento das imagens</li>\n",
    "  <li>Aumento das Epoch</li>\n",
    "  <li>Adcição de parte de treinamento</li>\n",
    "</ol>\n",
    "Datset (DriveDataset)\n",
    "<ol>\n",
    "  <li>Criação</li>\n",
    "  <li>Inclusão da biblioteca 'albumentations' para aumentar o numero de imagens do dataset</li>\n",
    "  <li></li>\n",
    "</ol> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150b8a3-01f6-4cef-a4ab-838adca3e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Metricas após sem aumento dos dados**\n",
    "5 epoch\n",
    "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
    "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
    "Training: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
    "                                                       \n",
    "  0%|          | 0/1 [00:00<?, ?it/s]\n",
    "100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
    "Epoch:  20%|██        | 1/5 [00:00<00:03,  1.19it/s]\n",
    "------------------------------\n",
    "Train Loss EPOCH 1: 0.7450\n",
    "Valid Loss EPOCH 1: 0.7389\n",
    "------------------------------\n",
    "Epoch 2\n",
    "\n",
    "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
    "Training: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
    "                                                       \n",
    "  0%|          | 0/1 [00:00<?, ?it/s]\n",
    "100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
    "Epoch:  40%|████      | 2/5 [00:01<00:01,  1.61it/s]\n",
    "------------------------------\n",
    "Train Loss EPOCH 2: 0.7376\n",
    "Valid Loss EPOCH 2: 0.7316\n",
    "------------------------------\n",
    "Epoch 3\n",
    "\n",
    "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
    "Training: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
    "                                                       \n",
    "  0%|          | 0/1 [00:00<?, ?it/s]\n",
    "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
    "Epoch:  60%|██████    | 3/5 [00:01<00:01,  1.88it/s]\n",
    "------------------------------\n",
    "Train Loss EPOCH 3: 0.7293\n",
    "Valid Loss EPOCH 3: 0.7231\n",
    "------------------------------\n",
    "Epoch 4\n",
    "\n",
    "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
    "Training: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
    "                                                       \n",
    "  0%|          | 0/1 [00:00<?, ?it/s]\n",
    "100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
    "Epoch:  80%|████████  | 4/5 [00:02<00:00,  2.05it/s]\n",
    "------------------------------\n",
    "Train Loss EPOCH 4: 0.7200\n",
    "Valid Loss EPOCH 4: 0.7130\n",
    "------------------------------\n",
    "Epoch 5\n",
    "\n",
    "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
    "Training: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
    "                                                       \n",
    "  0%|          | 0/1 [00:00<?, ?it/s]\n",
    "100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
    "------------------------------\n",
    "Train Loss EPOCH 5: 0.7086\n",
    "Valid Loss EPOCH 5: 0.6993\n",
    "------------------------------\n",
    "Epoch: 100%|██████████| 5/5 [00:02<00:00,  1.94it/s]\n",
    "\n",
    "    \n",
    "Test Loss: 0.9303\n",
    "Test Dice: 0.0160\n",
    "Test IoU: 0.0081\n",
    "Test Accuracy: 0.3355\n",
    "Test Precision: 0.0099\n",
    "Test Recall: 0.0411\n",
    "Test F1-score: 0.0160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "995f6520-b9bc-4d48-abde-5615caf0e265",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unet_parts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, random_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUNetPyTorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdrive_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DriveDataset\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score,iou,recall,dice_coef,accuracy,precision\n",
      "File \u001b[0;32m~/Documentos/mestrado usp/materias/MAC5921-Deep Learning/EP2/UNetPyTorch/unet.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munet_parts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DoubleConv, DownSample, UpSample\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUNet\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, num_classes):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unet_parts'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from UNetPyTorch.unet import UNet\n",
    "from drive_dataset import DriveDataset\n",
    "from metrics import f1_score,iou,recall,dice_coef,accuracy,precision\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bfe9f30-4369-4c29-9c8c-65bfc2ce4357",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1038108664.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    from UNet-PyTorch.unet import UNet\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    LEARNING_RATE = 3e-4\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5\n",
    "    DATA_PATH = \"/home/os/Documentos/mestrado usp/materias/MAC5921-Deep Learning/EP2/UNet-PyTorch/data_drive/traning\"\n",
    "    DATA_PATH_TESTE = \"/home/os/Documentos/mestrado usp/materias/MAC5921-Deep Learning/EP2/UNet-PyTorch/data_drive/testing\"\n",
    "    MODEL_SAVE_PATH = \"./models/unet.pth\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_dataset = DriveDataset(DATA_PATH,resize_size=(128,128))\n",
    "    test_dataset = DriveDataset(DATA_PATH_TESTE, resize_size=(128, 128))\n",
    "\n",
    "\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [0.8, 0.2], generator=generator)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=True)\n",
    "\n",
    "    model = UNet(in_channels=3, num_classes=1).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), colour=\"blue\", desc=\"Epoch\", leave=True):\n",
    "        model.train()\n",
    "        train_running_loss = 0\n",
    "        for idx, img_mask in enumerate(tqdm(train_dataloader, colour=\"green\",\n",
    "                                            desc=\"Training\", leave=False)):\n",
    "            img = img_mask[0].float().to(device)\n",
    "            mask = img_mask[1].float().to(device)\n",
    "\n",
    "            y_pred = model(img)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = criterion(y_pred, mask)\n",
    "            train_running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_running_loss / (idx + 1)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_running_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, img_mask in enumerate(tqdm(val_dataloader)):\n",
    "                img = img_mask[0].float().to(device)\n",
    "                mask = img_mask[1].float().to(device)\n",
    "\n",
    "                y_pred = model(img)\n",
    "                loss = criterion(y_pred, mask)\n",
    "\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "            val_loss = val_running_loss / (idx + 1)\n",
    "\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Impressão das métricas de treinamento e validação\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Train Loss EPOCH {epoch + 1}: {train_loss:.4f}\")\n",
    "        print(f\"Valid Loss EPOCH {epoch + 1}: {val_loss:.4f}\")\n",
    "        print(\"-\" * 30)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Salvar o modelo\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "    # Plotando a convergência da função de perda\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "    # Carregar o modelo treinado\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "    # Variáveis para armazenar métricas\n",
    "    test_running_loss = 0\n",
    "    test_running_dice = 0\n",
    "    test_running_iou = 0\n",
    "    test_running_accuracy = 0\n",
    "    test_running_precision = 0\n",
    "    test_running_recall = 0\n",
    "    test_running_f1 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, img_mask in enumerate(tqdm(test_dataloader, colour=\"yellow\", desc=\"Testando\", leave=False)):\n",
    "            img = img_mask[0].float().to(device)\n",
    "            mask = img_mask[1].float().to(device)\n",
    "\n",
    "            # Aplica threshold para obter a segmentação binária\n",
    "            y_pred = torch.sigmoid(model(img))\n",
    "            y_pred_bin = (y_pred > 0.5).float()\n",
    "\n",
    "            loss = criterion(y_pred, mask)\n",
    "\n",
    "            test_running_loss += loss.item()\n",
    "            test_running_dice += dice_coef(mask, y_pred_bin).item()\n",
    "            test_running_iou += iou(mask, y_pred_bin).item()\n",
    "            test_running_accuracy += accuracy(mask, y_pred_bin).item()\n",
    "            test_running_precision += precision(mask, y_pred_bin).item()\n",
    "            test_running_recall += recall(mask, y_pred_bin).item()\n",
    "            test_running_f1 += f1_score(mask, y_pred_bin).item()\n",
    "\n",
    "        test_loss = test_running_loss / (idx + 1)\n",
    "        test_dice = test_running_dice / (idx + 1)\n",
    "        test_iou = test_running_iou / (idx + 1)\n",
    "        test_accuracy = test_running_accuracy / (idx + 1)\n",
    "        test_precision = test_running_precision / (idx + 1)\n",
    "        test_recall = test_running_recall / (idx + 1)\n",
    "        test_f1 = test_running_f1 / (idx + 1)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Dice: {test_dice:.4f}\")\n",
    "    print(f\"Test IoU: {test_iou:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1-score: {test_f1:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ep2)",
   "language": "python",
   "name": "ep2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
